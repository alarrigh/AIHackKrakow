{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Prices Prediction\n",
    "### Model Deployment to Azure Container Instances (ACI) and Azure Kubernetes Services (AKS)\n",
    "\n",
    "We finished the last Notebook by finding best fitting model using AutoML and registering it to our AML account. In this Notebook, we deploy this model to an ACI instance and test it by scoring in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing the necessary packages and setting some notebook options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os, logging\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from pprint import pprint\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "from azureml.core.image import Image, ContainerImage\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "image_name = \"house-prices-img\"\n",
    "aci_service_name = \"house-prices-aci\"\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate a [Workspace](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspaces) object, using the information from the configuration file that we uploaded previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = open('config/ws_config.json')\n",
    "cred_dict = json.load(config_file)\n",
    "\n",
    "#auth = ServicePrincipalAuthentication(tenant_id = cred_dict['tentant_id'], \n",
    "#                                      service_principal_id = cred_dict['service_principal_id'], \n",
    "#                                      service_principal_password = cred_dict['service_principal_password'])\n",
    "\n",
    "ws = Workspace.from_config(path=\"./config/ws_config.json\") #, auth = auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the deployment consists of pointing to the model we want to deploy. We can simply provide the model name, which was given to us at the time we registered the model (in a previous notebook). The easiest thing for us is to go to the Azure portal to look up the model name: from the AML Workspace page, click on the section called **Models**. Once you find the model, copy its name. You will need to paste it in two separate cells below.\n",
    "\n",
    "Here's a quick sanity check to ensure that the model exists and can be loaded (loading the model in the current session is not required for deployment). Copy and paste the model name from the previous notebook in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "model_name = \"###################\" # PASTE MODEL NAME HERE\n",
    "\n",
    "model = Model(workspace = ws, name = model_name)\n",
    "print(model.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a scoring script that will run every time we make a call to the deployed model. The scoring script consists of an `init` function that will load the model and a `run` function that will load the data we provide at score time and use the model to obtain predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import pickle\n",
    "import json\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "import azureml.train.automl\n",
    "\n",
    "model_name = \"###################\" # PASTE MODEL NAME HERE\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path(model_name = model_name)\n",
    "    model = joblib.load(model_path) # deserialize the model file back into a sklearn model\n",
    "\n",
    "def run(rawdata):\n",
    "    try:\n",
    "        data = json.loads(rawdata)['data']\n",
    "        data = pd.DataFrame.from_dict(data)\n",
    "        result = model.predict(data)\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n",
    "    return json.dumps({\"result\":result.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a `yml` file for the conda environment that will serve as runtime for the scoring script above. To ensure consistency of the scored results with the training results, the dependencies need to mirror development environment (used for model training), but pared down to what is needed for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile myenv.yml\n",
    "name: myenv\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - pip:\n",
    "    - scikit-learn==0.19.1\n",
    "    - azureml-sdk[automl]==1.0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the scoring script and conda environment file, we can now create a docker image that will host the scoring script and a Python executable that meets the conda requirement dependencies laid out in the YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_config = ContainerImage.image_configuration(runtime = \"python\",\n",
    "                                 execution_script = \"score.py\",\n",
    "                                 conda_file = \"myenv.yml\",\n",
    "                                 tags = {'area': \"housing\", 'type': \"automl_classification\"},\n",
    "                                 description = \"Image for housing price prediction using AutoML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the image config file above we now create a Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "image = Image.create(name = image_name,\n",
    "                     models = [model], \n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the image creation fails, this is how we can access the log file and examine what went wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.image_build_log_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the image location that will be used when the imaged is pulled down. Creating a new image with the same name will result in a new version of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.image_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if the image was created in another session and we just wanted to point to it in this session, then we can just pass the image name and workspace to the `Image` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image(name = image_name, workspace = ws)\n",
    "print(image.image_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to deploy our image as a web service on ACI. To do so, we first create a config file and then pass it to `deploy_from_image` along with a name for the service, the image we created in the last step, and our AML Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = {\"method\" : \"automl\"}, \n",
    "                                               description = 'Predictive maintenance using auto-ml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a service with the same name already exists, we can delete it by calling the `delete` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aci_service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the service creation fails we can uncomment and the next cell to check out the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(aci_service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to test our web service. To begin with, we will point to our service using `Webservice`. Note that we've already done this in the last step, so in the current session this is not a necessary step, but since we want to be able to test the service from any Python session, we will point to the service again here. There is next to no overhead in doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service = Webservice(workspace = ws, name = aci_service_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now proceed to testing the service. To do so, we have a sample json file with some data in it. This will act as the data that we use for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = open(\"sample_data.json\", encoding = 'utf8').read()\n",
    "print(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass this data to the service using the `run` method, and it will return the predictions to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = aci_service.run(input_data = test_samples)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have Postman or any other REST client you can also test the scoring service against it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
